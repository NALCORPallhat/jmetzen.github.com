{
 "metadata": {
  "name": "",
  "signature": "sha256:05262978422481976189fc9663d3c4281f1c63d7097cfefcb6b77738bad9c7ae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sparse filtering on Olivetti faces\n",
      "================================== \n",
      "\n",
      "Unsupervised learning of features for images from the Olivetti faces dataset\n",
      "using the sparse filtering algorithm. Linear features for sub-patches of the\n",
      "Olivetti faces are learned using the sparse filtering algorithm. This algorithm\n",
      "does not try to model the data's distribution but rather to learn features which\n",
      "are sparsely activated (in the sense that for each image, only a small subset of\n",
      "features is activated, that each feature is only activated on a small subset of\n",
      "the examples, and that features are roughly activated equally often). This\n",
      "sparsity is encoded as an objective function and L-BFGS is used to minimize this\n",
      "function.\n",
      "\n",
      "Plotted are the weight matrices of the features (corresponding roughly to gabor\n",
      "filters) and feature activation histograms."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pylab as plt\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Install with \"pip install sparse_filtering\"\n",
      "from sparse_filtering import SparseFiltering"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load Olivetti faces data, normalize faces, and convert 2d structures\n",
      "from sklearn.datasets import fetch_olivetti_faces\n",
      "dataset = fetch_olivetti_faces(shuffle=True)\n",
      "faces = dataset.data\n",
      "\n",
      "n_samples, _ = faces.shape\n",
      "\n",
      "faces_centered = faces - faces.mean(axis=0)  # global centering\n",
      "\n",
      "faces_centered -= \\\n",
      "    faces_centered.mean(axis=1).reshape(n_samples, -1)  # local centering\n",
      "\n",
      "faces_centered = \\\n",
      "    faces_centered.reshape(n_samples, 64, 64)  # Reshaping to 64*64 pixel images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Dataset consists of %d faces\" % n_samples)\n",
      "plt.imshow(faces_centered[0], cmap=plt.get_cmap('gray'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract 25 16x16 patches randomly from each image\n",
      "from sklearn.feature_extraction.image import extract_patches_2d\n",
      "patch_width = 16\n",
      "\n",
      "patches = [extract_patches_2d(faces_centered[i], (patch_width, patch_width),\n",
      "                              max_patches=25, random_state=i)\n",
      "              for i in range(n_samples)]\n",
      "patches = np.array(patches).reshape(-1, patch_width * patch_width)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(8, 8))\n",
      "for i in range(25):\n",
      "    plt.subplot(5, 5, i+1)\n",
      "    plt.imshow(patches[i].reshape(patch_width, patch_width), cmap=plt.get_cmap('gray'))\n",
      "    plt.xticks([])\n",
      "    plt.yticks([])\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_features = 64   # How many features are learned\n",
      "estimator = SparseFiltering(n_features=n_features, \n",
      "                            maxfun=200,  # The maximal number of evaluations of the objective function\n",
      "                            iprint=10)  # after how many function evaluations is information printed\n",
      "                                        # by L-BFGS. -1 for no information\n",
      "features = estimator.fit_transform(patches)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print estimator.w_[1].max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 10))\n",
      "for i in range(estimator.w_.shape[0]):\n",
      "    plt.subplot(int(np.sqrt(n_features)), int(np.sqrt(n_features)), i + 1)\n",
      "    plt.pcolor(estimator.w_[i].reshape(patch_width, patch_width),\n",
      "               cmap=plt.cm.RdYlGn, vmin=estimator.w_.min(),\n",
      "               vmax=estimator.w_.max())\n",
      "    plt.xticks(())\n",
      "    plt.yticks(())\n",
      "    plt.title(\"Feature %4d\" % i)\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature activation histogram\n",
      "============================\n",
      "\n",
      "Features should have small activation typically "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(features.flat, bins=50)\n",
      "plt.xlabel(\"Activation\")\n",
      "plt.ylabel(\"Count\")\n",
      "_ = plt.title(\"Feature activation histogram\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lifetime Sparsity histogram\n",
      "===========================\n",
      "\n",
      "Lifetime Sparsity: Each feature should only be active (i.e., have an activation above 0.1) for a small ratio of the examples"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "activated_features = (features > 0.1).mean(1)\n",
      "plt.hist(activated_features)\n",
      "plt.xlabel(\"Feature activation ratio over all examples\")\n",
      "plt.ylabel(\"Count\")\n",
      "plt.title(\"Lifetime Sparsity Histogram\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot Population Sparsity histogram\n",
      "==================================\n",
      "\n",
      "Population Sparsity: Each example should activate only a few features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "activated_features = (features > 0.1).mean(0)\n",
      "plt.hist(activated_features, bins=10)\n",
      "plt.xlabel(\"Ratio of active features in example\")\n",
      "plt.ylabel(\"Count\")\n",
      "plt.title(\"Population Sparsity Histogram\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}